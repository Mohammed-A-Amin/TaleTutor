{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import tool\n",
    "from pydantic.v1 import BaseModel, Field\n",
    "from langchain.tools.render import format_tool_to_openai_function\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "import json\n",
    "from text2speech import *\n",
    "# from langchain_anthropic import ChatAnthropic\n",
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "#os.getenv(\"OPENAI_API_KEY\")\n",
    "#os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define knowledge LLM's function as a tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie=\"Harry Potter\"\n",
    "chapter= None\n",
    "initial_context= None\n",
    "subject= \"Physics\"\n",
    "chat_history= None\n",
    "\n",
    "movie_mapping= {\"Harry Potter\": \"Dumbledore\"}\n",
    "\n",
    "# Defining the knowledge_llm_func's input schema\n",
    "class knowledge_llm_func_schema(BaseModel):\n",
    "    user_query: str= Field(...,description= \"Query asked by the user\")\n",
    "    subject: str= Field(...,description=\"Subject name\")\n",
    "    chapter: str= Field(...,description=\"Chapter name\")\n",
    "\n",
    "\n",
    "@tool(args_schema=knowledge_llm_func_schema)\n",
    "def knowledge_llm_calling(user_query: str, subject= subject, chapter= chapter) -> str:\n",
    "# def knowledge_llm_calling(user_query: str, subject_chapter_tuple: list) -> str:\n",
    "    \"\"\"A function that can only answer questions on Physics subject on the Newton's Law of Motion chapter\"\"\"\n",
    "    return \"TEST\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Jupyter\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The method `BaseTool.__call__` was deprecated in langchain-core 0.1.47 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trasncript: Ah, my dear student, let me tell you a tale from the magical world of Harry Potter to explain Newton's Law of Motion. Imagine Harry zooming on his broomstick during a Quidditch match. When he suddenly stops, what do you think happens according to Newton's first law? Take a moment to think and share your answer with me, young one.\n",
      "chat_history AI: Ah, my dear student, let me tell you a tale from the magical world of Harry Potter to explain Newton's Law of Motion. Imagine Harry zooming on his broomstick during a Quidditch match. When he suddenly stops, what do you think happens according to Newton's first law? Take a moment to think and share your answer with me, young one.\n"
     ]
    }
   ],
   "source": [
    "# For reply with \n",
    "story_mode= ChatOpenAI(#model= ,\n",
    "    openai_api_key= os.getenv(\"OPENAI_API_KEY\"), \n",
    "    temperature=0, \n",
    "    #prompt=prompt\n",
    "    )\n",
    "\n",
    "def initial_user_input(st_name, subject_user, chapter_user, theme):\n",
    "    global subject, chapter, movie, initial_context, chat_history\n",
    "    subject= subject_user\n",
    "    chapter= chapter_user\n",
    "    movie= theme\n",
    "    initial_context= knowledge_llm_calling({'user_query': \"Explain in detail, what is {chapter}? \", 'subject': subject, 'chapter': chapter})\n",
    "    prompt= ChatPromptTemplate.from_messages([\n",
    "    (\"user\", \n",
    "        f\"\"\"\n",
    "    Imagine you are {movie_mapping[movie]} from the {movie} movie and you are going to teach me (your student) about {chapter}. Use the below context to teach:\n",
    "\n",
    "    Context: {initial_context}\n",
    "\n",
    "    Your teaching style:\n",
    "    * Teach concepts by narrating a story happening in the Harry Potter universe using characters from the movie.\n",
    "    * Use Dumbledore's slang and narrate the story from Dumbledore's POV.\n",
    "    * Treat me as a 10 year old kid\n",
    "    * Narrate a story and ask questions in between to guide me in the right path to learn the concepts. Occasionally, pause and conduct easy quiz to make sure I've understood the concepts correctly and  re-explain using if I'm wrong.\n",
    "    * After asking a question, wait for my response and ONLY PROCEED AFTER GETTING THE RESPONSE.\n",
    "    * Do not send more than 100 words in every iteration.\"\"\"\n",
    "        )\n",
    "    ])\n",
    "    chain_story_model= prompt | story_mode #| OpenAIFunctionsAgentOutputParser() | route_to_knowledge_llm    \n",
    "    story_llm_response =chain_story_model.invoke({\"chapter\":chapter,\"movie\": movie,\"initial_context\":initial_context})\n",
    "    chat_history = f\"AI: {story_llm_response.content}\"\n",
    "    trasncript= story_llm_response.content\n",
    "    print(\"trasncript:\", trasncript)\n",
    "    #audio_path= text_to_speech(trasncript)\n",
    "    print(\"chat_history\", chat_history)\n",
    "    #print(\"audio_path:\", audio_path)\n",
    "    \n",
    "   \n",
    "\n",
    "initial_user_input(\"Niranjan\", \"Physics\", \"Newton's Law of Motion\", \"Harry Potter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the story model's chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reply with \n",
    "story_mode1= ChatOpenAI(#model= ,\n",
    "    openai_api_key= os.getenv(\"OPENAI_API_KEY\"), \n",
    "    temperature=0, \n",
    "    #prompt=prompt\n",
    "    ).bind_tools(tools= [knowledge_llm_calling])\n",
    "\n",
    "prompt1= ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"If the user's input is a response to the your previous question in the mentioned chat history, continue the story. If the user has asked a new question from the Newton's Law of Function, ONLY THEN call the knowledge_llm_calling function. If the user's response is irrelevant to the subject and previous conversation, remind to get back to the topic and gently continue\"),\n",
    "    (\"user\", \"Chat History is: {chat_history} User's input is:{user_input}\")    \n",
    "])\n",
    "\n",
    "chain_story_model1= prompt1 | story_mode1 #| OpenAIFunctionsAgentOutputParser() | route_to_knowledge_llm\n",
    "\n",
    "# For reply with knowledge LLM's result\n",
    "story_mode2= ChatOpenAI(#model= ,\n",
    "    openai_api_key= os.getenv(\"OPENAI_API_KEY\"), \n",
    "    temperature=0, \n",
    "    )\n",
    "\n",
    "prompt2= ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You have been teaching the user in Dumbledoor's slang and the user has asked you the below provided question. See if the below provided context can be used to answer the question. If yes, answer it. If NOT, say the teacher will address that question and continue the previous conversation.\"),\n",
    "    (\"user\", \"Chat History is: {chat_history} \\n\\n User's question is: {user_input} \\n\\n Context is: {new_content}\")    \n",
    "])\n",
    "\n",
    "chain_story_model2= prompt2 | story_mode2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function call\n",
    "\n",
    "def chat_user_input(user_input):\n",
    "    global subject, chapter, movie, initial_context, chat_history\n",
    "    # Inference 1\n",
    "    story_llm_response1 =chain_story_model1.invoke({'user_input':user_input , \"chapter\":chapter,\"subject\":subject,\"chat_history\":chat_history})\n",
    "    #story_llm_response =chain.invoke({'user_input': \"I know this concept, can you teach me what's Newton's Third Law please?\", \"chapter\":chapter,\"subject\":subject,\"chat_history\":chat_history })\n",
    "    #story_llm_response = chain.invoke({'user_input': \"Maybe Harry stay in the same place?\", \"chapter\":chapter,\"subject\":subject,\"chat_history\":chat_history })\n",
    "\n",
    "    if (story_llm_response1.content==''):\n",
    "        # Call the knowledge model function\n",
    "        function_name= story_llm_response1.additional_kwargs['tool_calls'][0]['function']['name']\n",
    "        function_args= json.loads(story_llm_response1.additional_kwargs['tool_calls'][0]['function']['arguments'])\n",
    "        #print(function_args)\n",
    "        new_content= knowledge_llm_calling(function_args)\n",
    "        story_llm_response2 =chain_story_model2.invoke({'user_input':user_input , 'new_content': new_content, \"chapter\":chapter,\"subject\":subject,\"chat_history\":chat_history })\n",
    "        chat_history += f\"\\n\\n Human:{user_input} \\n\\nAI: {story_llm_response2.content}\"\n",
    "        trasncript= story_llm_response2.content\n",
    "        #audio_path= text_to_speech(trasncript)\n",
    "        #print(\"audio_path:\", audio_path)\n",
    "        print(\"trasncript:\", trasncript)\n",
    "    else:\n",
    "        # Update the chat history\n",
    "        chat_history = str(chat_history) + f\"\\n\\n Human:{user_input} \\n\\nAI: {story_llm_response1.content}\"\n",
    "        trasncript= story_llm_response1.content\n",
    "        #audio_path= text_to_speech(trasncript)\n",
    "        #print(\"audio_path:\", audio_path)\n",
    "        print(\"trasncript:\", trasncript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trasncript: It's okay if you're not sure! Let's explore this together. In the world of Harry Potter, when Harry zooms on his broomstick during a Quidditch match and suddenly stops, according to Newton's first law, what do you think would happen to him? Take a moment to think about it.\n"
     ]
    }
   ],
   "source": [
    "chat_user_input(\"I honestly don't know\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trasncript: In the world of Harry Potter, if Harry zooms on his broomstick during a Quidditch match and suddenly stops, according to Newton's first law, he will remain in motion unless acted upon by an external force. This means that if he stops suddenly, he would continue moving forward in the air until another force, like the ground or air resistance, stops him. \n",
      "\n",
      "If you have any more questions or if you'd like to explore another scenario related to Newton's Laws of Motion, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "chat_user_input(\"He will remain same?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
